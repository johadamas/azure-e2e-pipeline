table_name = []

for i in dbutils.fs.ls('/mnt/ibex-bronze/SalesLT/'):
  table_name.append(i.name.split('/')[0])

table_name


####################

from pyspark.sql.functions import date_format, from_utc_timestamp
from pyspark.sql.types import TimestampType

for i in table_name:
    # Load data from the bronze container
    path = f'/mnt/cobra-bronze/SalesLT/{i}/{i}.parquet'
    df = spark.read.format('parquet').load(path)

    # Transform the data
    for col in df.columns:
        if 'Date' in col or 'date' in col:
            df = df.withColumn(col, date_format(from_utc_timestamp(df[col].cast(TimestampType()), "UTC"), "yyyy-MM-dd"))
    
    # Load the transformed data to the silver container
    output_path = f'/mnt/cobra-silver/SalesLT/{i}/'
    df.write.format('delta').mode('append').save(output_path)

    # Optionally, log the processed table
    print(f"Processed table: {i} and saved to: {output_path}")